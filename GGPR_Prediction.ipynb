{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdGhJSm7/HA4lmhHDBvV8k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from sklearn.gaussian_process import GaussianProcessRegressor\n","from sklearn.gaussian_process.kernels import Kernel, StationaryKernelMixin, NormalizedKernelMixin\n","import geopandas as gpd\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from scipy.optimize import fmin_l_bfgs_b\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","class SpatialSimilarityKernel(StationaryKernelMixin, NormalizedKernelMixin, Kernel):\n","    \"\"\"\n","    Spatial Similarity kernel class that extends scikit-learn's Gaussian Process kernels.\n","    Inherits from StationaryKernelMixin (for stationarity) and NormalizedKernelMixin.\n","    \"\"\"\n","\n","    def __init__(self, P_function, sigma_values, epsilon=0.0001):\n","        \"\"\"\n","        Initializes the spatial similarity kernel.\n","        :param P_function: An array of weights that will be used to combine the exponential terms (feature importance).\n","        :param sigma_values: An array of variance estimates for each feature, used in the exponential decay.\n","        :param epsilon: A small value added to diagonal elements for numerical stability.\n","        \"\"\"\n","        self.P_function = P_function\n","        self.sigma_values = sigma_values\n","        self.epsilon = epsilon\n","\n","    def _calculate_similarity(self, u, v):\n","        \"\"\"\n","        Computes element-wise exponential similarity between two matrices (u, v).\n","        Exponential decay is applied based on the squared differences scaled by sigma_values.\n","\n","        :param u: Feature matrix X (shape [n_samples, n_features])\n","        :param v: Feature matrix Y (shape [m_samples, n_features])\n","        :return: An array E_i containing spatial similarity for each feature.\n","        \"\"\"\n","        # Add extra dimensions to broadcast easily\n","        u = u[:, np.newaxis, :]\n","        v = v[np.newaxis, :, :]\n","\n","        # Compute squared differences between each pair of points\n","        sq_diff = (u - v) ** 2\n","\n","        # Calculate exponential decay for each feature using sigma_values\n","        E_i = np.exp(-((sq_diff) / (2 * (self.sigma_values))))\n","        return E_i\n","\n","    def __call__(self, X, Y=None, eval_gradient=False):\n","        \"\"\"\n","        Main function used by GaussianProcessRegressor to compute the kernel matrix.\n","\n","        :param X: Feature matrix of shape [n_samples, n_features]\n","        :param Y: (Optional) Another feature matrix. If None, use X for both.\n","        :param eval_gradient: (Unused) Determines if gradient is computed, not used here.\n","        :return: The kernel similarity matrix of shape [n_samples, m_samples].\n","        \"\"\"\n","        if Y is None:\n","            Y = X\n","\n","        # Get exponential similarities feature-wise\n","        E_i = self._calculate_similarity(X, Y)\n","\n","        # Weighted average across features using P_function as weights\n","        S_uv = np.average(E_i, axis=2, weights=self.P_function)\n","        return S_uv\n","\n","    def diag(self, X):\n","        \"\"\"\n","        Returns the diagonal of the kernel matrix for a given X.\n","        Includes a small epsilon for numerical stability.\n","        \"\"\"\n","        return np.diag(np.ones(X.shape[0])) + self.epsilon\n","\n","    def is_stationary(self):\n","        \"\"\"\n","        Indicates that the kernel is stationary (depends on distances, not absolute positions).\n","        \"\"\"\n","        return True\n","\n","\n","def loss_function(P_function, X_train, y_train, sigma_values, alpha=1e-0):\n","    \"\"\"\n","    Defines a loss function for optimization based on Gaussian Process Regressor predictions.\n","\n","    :param P_function: Current set of feature weights to be evaluated.\n","    :param X_train: Training features.\n","    :param y_train: Training target values.\n","    :param sigma_values: Array of variances used in the exponential similarity calculation.\n","    :param alpha: Regularization parameter for the Gaussian Process Regressor.\n","    :return: RMSE (root mean squared error) for the given set of feature weights.\n","    \"\"\"\n","    # Instantiate the spatial similarity kernel with the current P_function\n","    kernel = SpatialSimilarityKernel(P_function=P_function, sigma_values=sigma_values)\n","    # Create a GPR model with the spatial similarity kernel\n","    gpr = GaussianProcessRegressor(kernel=kernel, alpha=alpha, optimizer=None)\n","    # Fit the model on the training set\n","    gpr.fit(X_train, y_train)\n","    # Predict on the same training data\n","    y_pred = gpr.predict(X_train, return_std=False)\n","    # Compute the RMSE for this set of predictions\n","    rmse = mean_squared_error(y_train, y_pred, squared=False)\n","    return rmse\n","\n","def objective(P_function):\n","    \"\"\"\n","    Wrapper function for the optimizer (fmin_l_bfgs_b).\n","    Returns the RMSE for the current P_function, which the optimizer tries to minimize.\n","    \"\"\"\n","    return loss_function(P_function, X_train, y_train, sigma_values, alpha=1e-0)\n","\n","# Load data\n","chicago = gpd.read_file(\"/data/chicago_scv.geojson\")\n","chicago['pct_white'] = 1 - chicago['pct_nonwhi']\n","chicago['PD_log'] = np.log(chicago['population'])\n","y = np.log(chicago['TripCount'].values)\n","\n","# Select features\n","X_vars = ['pct_white','pct_bachel', 'pct_no_veh','PD_log','job_entrop','TripMiles_']\n","X = chicago[X_vars]\n","\n","# Standardize the feature matrix\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.9, random_state=999)\n","\n","# Compute the variance of each feature in the training set\n","sigma_values = np.array(np.var(X_train, axis=0))\n","\n","# Initialize P_function (weights) for all features\n","initial_P_function = np.ones(len(X_vars)) * 1\n","\n","# Set bounds for each weight (between 0 and 5)\n","bounds = [(0, 5)] * len(X_vars)\n","\n","# Use L-BFGS-B to optimize the objective function\n","optimized_P_function, min_loss, info = fmin_l_bfgs_b(\n","    objective,\n","    initial_P_function,\n","    bounds=bounds,\n","    approx_grad=True\n",")\n","\n","print(\"Optimized P_function: \", optimized_P_function)\n","\n","# Build a GaussianProcessRegressor using the optimized weights\n","kernel = SpatialSimilarityKernel(P_function=optimized_P_function, sigma_values=sigma_values)\n","gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-1, optimizer=None)\n","\n","# Fit the final model on the training data\n","gpr.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = gpr.predict(X_test, return_std=False)\n","\n","# Compute metrics (MSE, MAE, MAPE, R²) on the test set\n","mse = mean_squared_error(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","mape = mean_absolute_percentage_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","r2 = round(r2, 4)\n","\n","print(\"MSE: \", mse.round(4))\n","print(\"MAE: \", mae.round(4))\n","print(\"MAPE: \", mape.round(4))\n","print(\"R² Score: \", r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJJbkDe7CL0s","executionInfo":{"status":"ok","timestamp":1732718045232,"user_tz":-480,"elapsed":3896,"user":{"displayName":"Joseph Jiao","userId":"15208460091880993566"}},"outputId":"11b6fb90-3a10-4894-fba8-6d0b82683789"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimized P_function:  [0.04688675 2.24758405 0.43979082 0.71099497 0.12188657 1.72973757]\n","MSE:  0.6014\n","MAE:  0.5837\n","MAPE:  0.0661\n","R² Score:  0.8223\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.gaussian_process import GaussianProcessRegressor\n","from sklearn.gaussian_process.kernels import Kernel, StationaryKernelMixin, NormalizedKernelMixin\n","import geopandas as gpd\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from scipy.optimize import fmin_l_bfgs_b\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","class SpatialSimilarityKernel(StationaryKernelMixin, NormalizedKernelMixin, Kernel):\n","    \"\"\"\n","    Spatial Similarity kernel class that extends scikit-learn's Gaussian Process kernels.\n","    Inherits from StationaryKernelMixin (for stationarity) and NormalizedKernelMixin.\n","    \"\"\"\n","\n","    def __init__(self, P_function, sigma_values, epsilon=0.0001):\n","        \"\"\"\n","        Initializes the spatial similarity kernel.\n","        :param P_function: An array of weights that will be used to combine the exponential terms (feature importance).\n","        :param sigma_values: An array of variance estimates for each feature, used in the exponential decay.\n","        :param epsilon: A small value added to diagonal elements for numerical stability.\n","        \"\"\"\n","        self.P_function = P_function\n","        self.sigma_values = sigma_values\n","        self.epsilon = epsilon\n","\n","    def _calculate_similarity(self, u, v):\n","        \"\"\"\n","        Computes element-wise exponential similarity between two matrices (u, v).\n","        Exponential decay is applied based on the squared differences scaled by sigma_values.\n","\n","        :param u: Feature matrix X (shape [n_samples, n_features])\n","        :param v: Feature matrix Y (shape [m_samples, n_features])\n","        :return: An array E_i containing spatial similarity for each feature.\n","        \"\"\"\n","        # Add extra dimensions to broadcast easily\n","        u = u[:, np.newaxis, :]\n","        v = v[np.newaxis, :, :]\n","\n","        # Compute squared differences between each pair of points\n","        sq_diff = (u - v) ** 2\n","\n","        # Calculate exponential decay for each feature using sigma_values\n","        E_i = np.exp(-((sq_diff) / (2 * (self.sigma_values))))\n","        return E_i\n","\n","    def __call__(self, X, Y=None, eval_gradient=False):\n","        \"\"\"\n","        Main function used by GaussianProcessRegressor to compute the kernel matrix.\n","\n","        :param X: Feature matrix of shape [n_samples, n_features]\n","        :param Y: (Optional) Another feature matrix. If None, use X for both.\n","        :param eval_gradient: (Unused) Determines if gradient is computed, not used here.\n","        :return: The kernel similarity matrix of shape [n_samples, m_samples].\n","        \"\"\"\n","        if Y is None:\n","            Y = X\n","\n","        # Get exponential similarities feature-wise\n","        E_i = self._calculate_similarity(X, Y)\n","\n","        # Weighted average across features using P_function as weights\n","        S_uv = np.average(E_i, axis=2, weights=self.P_function)\n","        return S_uv\n","\n","    def diag(self, X):\n","        \"\"\"\n","        Returns the diagonal of the kernel matrix for a given X.\n","        Includes a small epsilon for numerical stability.\n","        \"\"\"\n","        return np.diag(np.ones(X.shape[0])) + self.epsilon\n","\n","    def is_stationary(self):\n","        \"\"\"\n","        Indicates that the kernel is stationary (depends on distances, not absolute positions).\n","        \"\"\"\n","        return True\n","\n","\n","def loss_function(P_function, X_train, y_train, sigma_values, alpha=1e-1):\n","    \"\"\"\n","    Defines a loss function for optimization based on Gaussian Process Regressor predictions.\n","\n","    :param P_function: Current set of feature weights to be evaluated.\n","    :param X_train: Training features.\n","    :param y_train: Training target values.\n","    :param sigma_values: Array of variances used in the exponential similarity calculation.\n","    :param alpha: Regularization parameter for the Gaussian Process Regressor.\n","    :return: RMSE (root mean squared error) for the given set of feature weights.\n","    \"\"\"\n","    # Instantiate the spatial similarity kernel with the current P_function\n","    kernel = SpatialSimilarityKernel(P_function=P_function, sigma_values=sigma_values)\n","\n","    # Create a GPR model with the spatial similarity kernel\n","    gpr = GaussianProcessRegressor(kernel=kernel, alpha=alpha, optimizer=None)\n","\n","    # Fit the model on the training set\n","    gpr.fit(X_train, y_train)\n","\n","    # Predict on the same training data\n","    y_pred = gpr.predict(X_train, return_std=False)\n","\n","    # Compute the RMSE for this set of predictions\n","    rmse = mean_squared_error(y_train, y_pred, squared=False)\n","    return rmse\n","\n","def objective(P_function):\n","    \"\"\"\n","    Wrapper function for the optimizer (fmin_l_bfgs_b).\n","    Returns the RMSE for the current P_function, which the optimizer tries to minimize.\n","    \"\"\"\n","    return loss_function(P_function, X_train, y_train, sigma_values, alpha=1e-1)\n","\n","\n","# Load data\n","Berxit = gpd.read_file(\"/data/leave_data.geojson\")\n","y = Berxit['leave'].values\n","X_vars = ['to15','over65','lhosp','manu','badhealth','bornuk']\n","X = Berxit[X_vars]\n","\n","# Standardize feature matrix\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Standardize the target as well\n","y_scaler = StandardScaler()\n","y_scaled = y_scaler.fit_transform(y.reshape(-1, 1))\n","\n","# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.9, random_state=42)\n","\n","# Compute the variance of each feature in the training set\n","sigma_values = np.array(np.var(X_train, axis=0))\n","\n","# Initialize P_function (weights) for all features\n","initial_P_function = np.ones(len(X_vars)) * 1\n","\n","# Set bounds for each weight (between 0 and 5)\n","bounds = [(0, 5)] * len(X_vars)\n","\n","# Use L-BFGS-B to optimize the objective function\n","optimized_P_function, min_loss, info = fmin_l_bfgs_b(\n","    objective,\n","    initial_P_function,\n","    bounds=bounds,\n","    approx_grad=True\n",")\n","\n","print(\"Optimized P_function: \", optimized_P_function)\n","\n","# Build a GaussianProcessRegressor using the optimized weights\n","kernel = SpatialSimilarityKernel(P_function=optimized_P_function, sigma_values=sigma_values)\n","gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-1, optimizer=None)\n","\n","# Fit the final model on the training data\n","gpr.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = gpr.predict(X_test, return_std=False)\n","\n","# Compute metrics (MSE, MAE, MAPE, R²) on the test set\n","mse = mean_squared_error(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","mape = mean_absolute_percentage_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","r2 = round(r2, 4)\n","\n","print(\"MSE: \", mse.round(4))\n","print(\"MAE: \", mae.round(4))\n","print(\"MAPE: \", mape.round(4))\n","print(\"R² Score: \", r2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pebRrezACnT-","executionInfo":{"status":"ok","timestamp":1732718214740,"user_tz":-480,"elapsed":1200,"user":{"displayName":"Joseph Jiao","userId":"15208460091880993566"}},"outputId":"a453f58c-1f11-4f13-a0a4-2f46df83457f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimized P_function:  [1.53809149 1.69200801 0.58865995 0.23002332 0.78079264 0.41889233]\n","MSE:  0.3735\n","MAE:  0.4637\n","MAPE:  1.7959\n","R² Score:  0.6193\n"]}]}]}